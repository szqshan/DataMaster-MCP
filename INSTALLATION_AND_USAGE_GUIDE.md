# ğŸ“Š DataMaster MCP å®Œæ•´å®‰è£…ä½¿ç”¨æŒ‡å—

> **è¶…çº§æ•°æ®åˆ†æMCPå·¥å…·** - ä¸ºAIæä¾›å¼ºå¤§çš„æ•°æ®åˆ†æèƒ½åŠ›çš„å®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸ¯ ä»€ä¹ˆæ˜¯ DataMaster MCPï¼Ÿ

**DataMaster MCP** æ˜¯ä¸€ä¸ªä¸“ä¸º Claude Desktop è®¾è®¡çš„æ•°æ®åˆ†æå·¥å…·ï¼Œå®ƒè®©AIèƒ½å¤Ÿï¼š
- ğŸ“ è¿æ¥å„ç§æ•°æ®æºï¼ˆExcelã€CSVã€æ•°æ®åº“ã€APIï¼‰
- ğŸ” æ‰§è¡Œå¤æ‚çš„æ•°æ®æŸ¥è¯¢å’Œåˆ†æ
- ğŸ“Š è¿›è¡Œç»Ÿè®¡åˆ†æå’Œæ•°æ®è´¨é‡æ£€æŸ¥
- ğŸ› ï¸ å¤„ç†å’Œæ¸…æ´—æ•°æ®
- ğŸ“¤ å¯¼å‡ºåˆ†æç»“æœ

**æ ¸å¿ƒç†å¿µï¼šå·¥å…·ä¸“æ³¨æ•°æ®è·å–å’Œè®¡ç®—ï¼ŒAIä¸“æ³¨æ™ºèƒ½åˆ†æå’Œæ´å¯Ÿ**

---

## ğŸ“Š æ ¸å¿ƒåŠŸèƒ½æ¦‚è§ˆ

### ğŸ”— æ•°æ®æºè¿æ¥
- **Excel/CSVæ–‡ä»¶å¯¼å…¥** - æ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç 
- **æ•°æ®åº“è¿æ¥** - MySQLã€PostgreSQLã€MongoDBã€SQLite
- **APIæ•°æ®è·å–** - RESTful APIè¿æ¥å’Œæ•°æ®æå–

### ğŸ” æ•°æ®æŸ¥è¯¢åˆ†æ
- **SQLæŸ¥è¯¢æ‰§è¡Œ** - æœ¬åœ°å’Œå¤–éƒ¨æ•°æ®åº“æŸ¥è¯¢
- **æ•°æ®ç»Ÿè®¡åˆ†æ** - åŸºç¡€ç»Ÿè®¡ã€ç›¸å…³æ€§ã€å¼‚å¸¸å€¼æ£€æµ‹
- **æ•°æ®è´¨é‡æ£€æŸ¥** - ç¼ºå¤±å€¼ã€é‡å¤å€¼åˆ†æ

### ğŸ› ï¸ æ•°æ®å¤„ç†
- **æ•°æ®æ¸…æ´—** - å»é‡ã€å¡«å……ç¼ºå¤±å€¼
- **æ•°æ®è½¬æ¢** - ç±»å‹è½¬æ¢ã€æ ¼å¼åŒ–
- **æ•°æ®èšåˆ** - åˆ†ç»„ç»Ÿè®¡ã€æ±‡æ€»

### ğŸ“¤ æ•°æ®å¯¼å‡º
- **å¤šæ ¼å¼å¯¼å‡º** - Excelã€CSVã€JSON
- **æŸ¥è¯¢ç»“æœå¯¼å‡º** - æ”¯æŒSQLæŸ¥è¯¢ç»“æœå¯¼å‡º

---

## ğŸš€ å¿«é€Ÿå®‰è£…

### æ–¹æ³•ä¸€ï¼špip å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# å®‰è£… DataMaster MCP
pip install datamaster-mcp

# éªŒè¯å®‰è£…
pip show datamaster-mcp
```

### æ–¹æ³•äºŒï¼šå¼€å‘è€…å®‰è£…

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/szqshan/DataMaster.git
cd DataMaster

# 2. è‡ªåŠ¨è®¾ç½®å¼€å‘ç¯å¢ƒ
python scripts/setup_dev.py

# 3. æµ‹è¯•ç¯å¢ƒ
python scripts/setup_dev.py --test-only
```

---

## âš™ï¸ Claude Desktop é…ç½®

### ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°é…ç½®æ–‡ä»¶

**Windows ç³»ç»Ÿï¼š**
```
%APPDATA%\Claude\claude_desktop_config.json
```

**macOS ç³»ç»Ÿï¼š**
```
~/Library/Application Support/Claude/claude_desktop_config.json
```

**Linux ç³»ç»Ÿï¼š**
```
~/.config/Claude/claude_desktop_config.json
```

### ç¬¬äºŒæ­¥ï¼šé…ç½® MCP æœåŠ¡å™¨

#### ğŸš€ æ¨èé…ç½®ï¼ˆä½¿ç”¨ uvxï¼‰

é¦–å…ˆå®‰è£… uvï¼š
```bash
# Windows
scoop install uv
# æˆ–è€…
pip install uv
```

ç„¶ååœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ï¼š
```json
{
  "mcpServers": {
    "datamaster-mcp": {
      "command": "uvx",
      "args": [
        "datamaster-mcp"
      ]
    }
  }
}
```

#### ğŸ”§ å¤‡ç”¨é…ç½®ï¼ˆä½¿ç”¨æ¨¡å—è·¯å¾„ï¼‰

```json
{
  "mcpServers": {
    "datamaster-mcp": {
      "command": "python",
      "args": [
        "-m",
        "datamaster_mcp.main"
      ]
    }
  }
}
```

### ç¬¬ä¸‰æ­¥ï¼šé‡å¯ Claude Desktop

é…ç½®å®Œæˆåï¼Œå®Œå…¨å…³é—­å¹¶é‡æ–°å¯åŠ¨ Claude Desktop åº”ç”¨ã€‚

### ç¬¬ä¸‰æ­¥ï¼šé«˜çº§é…ç½®ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡æˆ–å·¥ä½œç›®å½•ï¼š

```json
{
  "mcpServers": {
    "datamaster-mcp": {
      "command": "python",
      "args": [
        "-m",
        "datamaster_mcp.main"
      ],
      "env": {
        "DATAMASTER_CONFIG_PATH": "C:\\path\\to\\your\\config"
      },
      "cwd": "C:\\path\\to\\working\\directory"
    }
  }
}
```

### ç¬¬å››æ­¥ï¼šéªŒè¯é…ç½®

åœ¨ Claude Desktop ä¸­æµ‹è¯•ï¼š
```
è¯·å¸®æˆ‘è¿æ¥ä¸€ä¸ªæ•°æ®æº
```

æˆ–è€…ï¼š
```
æ˜¾ç¤ºå¯ç”¨çš„æ•°æ®åˆ†æå·¥å…·
```

## ğŸš¨ å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜ 1ï¼šæ‰¾ä¸åˆ°æ¨¡å—

**é”™è¯¯ä¿¡æ¯ï¼š** `ModuleNotFoundError: No module named 'datamaster_mcp'`

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®è®¤å·²æ­£ç¡®å®‰è£…ï¼š`pip show datamaster-mcp`
2. æ£€æŸ¥ Python è·¯å¾„æ˜¯å¦æ­£ç¡®
3. å°è¯•ä½¿ç”¨å®Œæ•´è·¯å¾„é…ç½®

### é—®é¢˜ 2ï¼šæƒé™é”™è¯¯

**é”™è¯¯ä¿¡æ¯ï¼š** `Permission denied`

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®ä¿ Python æœ‰æ‰§è¡Œæƒé™
2. åœ¨ Windows ä¸Šå¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™
3. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®

### é—®é¢˜ 3ï¼šé…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯

**é”™è¯¯ä¿¡æ¯ï¼š** JSON è§£æé”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ JSON æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆæ³¨æ„é€—å·ã€å¼•å·ï¼‰
2. ä½¿ç”¨ JSON éªŒè¯å·¥å…·æ£€æŸ¥è¯­æ³•
3. ç¡®ä¿è·¯å¾„ä¸­çš„åæ–œæ æ­£ç¡®è½¬ä¹‰ï¼ˆWindowsï¼‰

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½¿ç”¨æ¨¡å—è·¯å¾„
æ¨èä½¿ç”¨ `-m datamaster_mcp.main` æ–¹å¼ï¼Œè¿™æ ·ä¸ä¾èµ–å…·ä½“çš„å®‰è£…è·¯å¾„ã€‚

### 2. å¤‡ä»½é…ç½®
åœ¨ä¿®æ”¹é…ç½®å‰ï¼Œå…ˆå¤‡ä»½åŸæœ‰çš„ `claude_desktop_config.json` æ–‡ä»¶ã€‚

### 3. é€æ­¥æµ‹è¯•
å…ˆä½¿ç”¨æœ€ç®€å•çš„é…ç½®ï¼Œç¡®è®¤èƒ½æ­£å¸¸å·¥ä½œåå†æ·»åŠ é«˜çº§é€‰é¡¹ã€‚

---

## ğŸ“š åŸºç¡€ä½¿ç”¨æ•™ç¨‹

### 1. æ•°æ®åº“è¿æ¥åŠŸèƒ½

#### æ”¯æŒçš„æ•°æ®åº“ç±»å‹

- **MySQL** - å…³ç³»å‹æ•°æ®åº“
- **PostgreSQL** - å…³ç³»å‹æ•°æ®åº“  
- **MongoDB** - æ–‡æ¡£å‹æ•°æ®åº“
- **SQLite** - è½»é‡çº§å…³ç³»å‹æ•°æ®åº“

#### è¿æ¥æ–¹å¼

##### æ–¹å¼ä¸€ï¼šé…ç½®æ–‡ä»¶è¿æ¥ï¼ˆæ¨èï¼‰

1. **é…ç½®æ•°æ®åº“ä¿¡æ¯**

ç¼–è¾‘ `config/database_config.json`ï¼š

```json
{
  "databases": {
    "my_mysql": {
      "type": "mysql",
      "host": "localhost",
      "port": 3306,
      "database": "my_database",
      "username": "root",
      "password": "${MYSQL_PASSWORD}",
      "charset": "utf8mb4",
      "description": "æˆ‘çš„MySQLæ•°æ®åº“",
      "enabled": true
    },
    "my_postgres": {
      "type": "postgresql",
      "host": "localhost",
      "port": 5432,
      "database": "my_database",
      "username": "postgres",
      "password": "${POSTGRES_PASSWORD}",
      "schema": "public",
      "description": "æˆ‘çš„PostgreSQLæ•°æ®åº“",
      "enabled": true
    }
  }
}
```

2. **è®¾ç½®ç¯å¢ƒå˜é‡**

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```env
# æ•°æ®åº“å¯†ç 
MYSQL_PASSWORD=your_mysql_password
POSTGRES_PASSWORD=your_postgres_password
MONGO_PASSWORD=your_mongo_password
```

##### æ–¹å¼äºŒï¼šç›´æ¥è¿æ¥

```python
# MySQLè¿æ¥
connect_data_source(
    source_type="mysql",
    config={
        "host": "localhost",
        "port": 3306,
        "database": "test_db",
        "username": "root",  # æ”¯æŒ user æˆ– username
        "password": "password"
    }
)

# PostgreSQLè¿æ¥
connect_data_source(
    source_type="postgresql",
    config={
        "host": "localhost",
        "port": 5432,
        "database": "test_db",
        "username": "postgres",
        "password": "password"
    }
)
```

#### æ•°æ®åº“ç®¡ç†

```python
# åˆ—å‡ºæ‰€æœ‰é…ç½®
manage_database_config(action="list")

# æµ‹è¯•è¿æ¥
manage_database_config(
    action="test",
    config={"database_name": "my_mysql"}
)

# æ·»åŠ æ–°é…ç½®
manage_database_config(
    action="add",
    config={
        "database_name": "new_db",
        "database_config": {
            "type": "mysql",
            "host": "192.168.1.100",
            "port": 3306,
            "database": "test_db",
            "username": "user",
            "password": "pass"
        }
    }
)
```

### 2. æ–‡ä»¶å¯¼å…¥åŠŸèƒ½

#### Excelæ–‡ä»¶å¯¼å…¥

```python
connect_data_source(
    source_type="excel",
    config={
        "file_path": "data/sales.xlsx",
        "sheet_name": "Sheet1"  # å¯é€‰ï¼Œé»˜è®¤ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
    },
    target_table="sales_data"
)
```

#### CSVæ–‡ä»¶å¯¼å…¥

```python
connect_data_source(
    source_type="csv",
    config={
        "file_path": "data/customers.csv",
        "encoding": "utf-8"  # å¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹
    },
    target_table="customers"
)
```

### 2. APIè¿æ¥å™¨åŠŸèƒ½

#### æ”¯æŒçš„è®¤è¯æ–¹å¼

- **API Keyè®¤è¯** - é€šè¿‡Headeræˆ–Queryå‚æ•°
- **Bearer Tokenè®¤è¯** - JWTç­‰Tokenè®¤è¯
- **Basicè®¤è¯** - ç”¨æˆ·åå¯†ç è®¤è¯
- **OAuth 2.0** - æ ‡å‡†OAuthæµç¨‹
- **è‡ªå®šä¹‰Header** - çµæ´»çš„è®¤è¯æ–¹å¼

#### APIé…ç½®ç®¡ç†

##### é…ç½®APIè¿æ¥

ç¼–è¾‘ `config/api_config.json`ï¼š

```json
{
  "apis": {
    "weather_api": {
      "base_url": "https://api.openweathermap.org/data/2.5",
      "auth_type": "api_key",
      "auth_config": {
        "key": "${WEATHER_API_KEY}",
        "location": "query",
        "param_name": "appid"
      },
      "description": "å¤©æ°”æ•°æ®API",
      "enabled": true
    },
    "github_api": {
      "base_url": "https://api.github.com",
      "auth_type": "bearer",
      "auth_config": {
        "token": "${GITHUB_TOKEN}"
      },
      "description": "GitHub API",
      "enabled": true
    }
  }
}
```

#### APIç«¯ç‚¹è·å–

```python
# è·å–APIç«¯ç‚¹ä¿¡æ¯
get_api_endpoints(
    api_name="weather_api",
    endpoint="/weather",
    params={"q": "Beijing", "units": "metric"}
)

# è·å–GitHubä»“åº“ä¿¡æ¯
get_api_endpoints(
    api_name="github_api",
    endpoint="/repos/owner/repo"
)
```

#### APIæ•°æ®è·å–ä¸å­˜å‚¨

```python
# è·å–APIæ•°æ®å¹¶è‡ªåŠ¨å­˜å‚¨
get_api_data(
    api_name="weather_api",
    endpoint="/weather",
    params={"q": "Shanghai", "units": "metric"},
    store_data=True,
    table_name="weather_data"
)

# æ‰¹é‡è·å–æ•°æ®
cities = ["Beijing", "Shanghai", "Guangzhou"]
for city in cities:
    get_api_data(
        api_name="weather_api",
        endpoint="/weather",
        params={"q": city, "units": "metric"},
        store_data=True,
        table_name="weather_data"
    )
```

##### ä¼šè¯ç®¡ç†

- **è‡ªåŠ¨å­˜å‚¨** - APIå“åº”æ•°æ®è‡ªåŠ¨å­˜å‚¨åˆ°æœ¬åœ°æ•°æ®åº“
- **æ•°æ®æŒä¹…åŒ–** - æ”¯æŒè·¨ä¼šè¯æ•°æ®æŸ¥è¯¢
- **å¢é‡æ›´æ–°** - æ”¯æŒæ•°æ®å¢é‡è·å–å’Œæ›´æ–°

### 3. æ•°æ®æŸ¥è¯¢åŠŸèƒ½

#### æœ¬åœ°æ•°æ®æŸ¥è¯¢

```python
# åŸºæœ¬æŸ¥è¯¢
execute_sql("SELECT * FROM sales LIMIT 10")

# ç»Ÿè®¡æŸ¥è¯¢
execute_sql("SELECT COUNT(*) as total_sales FROM sales")

# åˆ†ç»„æŸ¥è¯¢
execute_sql("""
    SELECT category, SUM(amount) as total_amount 
    FROM sales 
    GROUP BY category
    ORDER BY total_amount DESC
""")

# å¤æ‚æŸ¥è¯¢
execute_sql("""
    SELECT 
        DATE(order_date) as date,
        COUNT(*) as order_count,
        SUM(amount) as total_revenue,
        AVG(amount) as avg_order_value
    FROM sales 
    WHERE order_date >= '2024-01-01'
    GROUP BY DATE(order_date)
    ORDER BY date
""")
```

#### å¤–éƒ¨æ•°æ®åº“æŸ¥è¯¢

```python
# æŸ¥è¯¢å¤–éƒ¨MySQLæ•°æ®åº“
query_external_database(
    database_name="my_mysql",
    query="SELECT * FROM products WHERE price > 100"
)

# æŸ¥è¯¢å¤–éƒ¨PostgreSQLæ•°æ®åº“
query_external_database(
    database_name="my_postgres",
    query="""
        SELECT p.name, p.price, c.name as category_name
        FROM products p
        JOIN categories c ON p.category_id = c.id
        WHERE p.created_at >= '2024-01-01'
    """
)
```

### 3. æ•°æ®åˆ†æåŠŸèƒ½

#### åŸºç¡€ç»Ÿè®¡åˆ†æ

```python
# è·å–æ•°æ®åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
analyze_data(
    table_name="sales",
    analysis_type="basic_stats"
)

# è·å–ç‰¹å®šåˆ—çš„ç»Ÿè®¡ä¿¡æ¯
analyze_data(
    table_name="sales",
    analysis_type="basic_stats",
    columns=["amount", "quantity"]
)

# åˆ†ç»„ç»Ÿè®¡
analyze_data(
    table_name="sales",
    analysis_type="group_stats",
    group_by="category",
    agg_column="amount"
)
```

#### æ•°æ®è´¨é‡æ£€æŸ¥

```python
# æ£€æŸ¥ç¼ºå¤±å€¼
analyze_data(
    table_name="customers",
    analysis_type="missing_values"
)

# æ£€æŸ¥é‡å¤å€¼
analyze_data(
    table_name="customers",
    analysis_type="duplicates",
    columns=["email"]  # æ£€æŸ¥é‚®ç®±é‡å¤
)

# æ•°æ®ç±»å‹æ£€æŸ¥
analyze_data(
    table_name="sales",
    analysis_type="data_types"
)

# æ•°æ®èŒƒå›´æ£€æŸ¥
analyze_data(
    table_name="sales",
    analysis_type="value_ranges",
    columns=["amount", "quantity"]
)
```

#### ç›¸å…³æ€§åˆ†æ

```python
# åˆ†ææ•°å€¼åˆ—ä¹‹é—´çš„ç›¸å…³æ€§
analyze_data(
    table_name="sales",
    analysis_type="correlation",
    columns=["amount", "quantity", "price"]
)

# è®¡ç®—ç‰¹å®šåˆ—çš„ç›¸å…³ç³»æ•°
analyze_data(
    table_name="sales",
    analysis_type="correlation_matrix",
    columns=["amount", "quantity", "discount"]
)
```

#### å¼‚å¸¸å€¼æ£€æµ‹

```python
# ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
analyze_data(
    table_name="sales",
    analysis_type="outliers",
    column="amount",
    method="iqr"
)

# ä½¿ç”¨Z-Scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
analyze_data(
    table_name="sales",
    analysis_type="outliers",
    column="amount",
    method="zscore",
    threshold=3
)
```

### 4. æ•°æ®å¤„ç†åŠŸèƒ½

#### æ•°æ®æ¸…æ´—

```python
# åˆ é™¤é‡å¤æ•°æ®
process_data(
    table_name="customers",
    operation="remove_duplicates",
    columns=["email"]  # åŸºäºé‚®ç®±å»é‡
)

# åˆ é™¤å®Œå…¨é‡å¤çš„è¡Œ
process_data(
    table_name="sales",
    operation="remove_duplicates"
)

# å¡«å……ç¼ºå¤±å€¼
process_data(
    table_name="sales",
    operation="fill_missing",
    column="amount",
    fill_value=0  # ç”¨0å¡«å……
)

# ç”¨å¹³å‡å€¼å¡«å……ç¼ºå¤±å€¼
process_data(
    table_name="sales",
    operation="fill_missing",
    column="price",
    fill_method="mean"
)

# ç”¨ä¸­ä½æ•°å¡«å……ç¼ºå¤±å€¼
process_data(
    table_name="sales",
    operation="fill_missing",
    column="quantity",
    fill_method="median"
)

# åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
process_data(
    table_name="customers",
    operation="drop_missing",
    columns=["email", "phone"]  # åˆ é™¤é‚®ç®±æˆ–ç”µè¯ä¸ºç©ºçš„è¡Œ
)
```

#### æ•°æ®è½¬æ¢

```python
# æ•°æ®ç±»å‹è½¬æ¢
process_data(
    table_name="sales",
    operation="convert_type",
    column="order_date",
    target_type="datetime"
)

# å­—ç¬¦ä¸²æ ¼å¼åŒ–
process_data(
    table_name="customers",
    operation="format_string",
    column="phone",
    format_pattern="xxx-xxxx-xxxx"
)

# æ•°å€¼æ ‡å‡†åŒ–
process_data(
    table_name="sales",
    operation="normalize",
    column="amount",
    method="min_max"  # æˆ– "z_score"
)
```

#### æ•°æ®ç­›é€‰

```python
# åŸºäºæ¡ä»¶ç­›é€‰æ•°æ®
process_data(
    table_name="sales",
    operation="filter",
    condition="amount > 1000 AND category = 'Electronics'"
)

# åŸºäºæ—¥æœŸèŒƒå›´ç­›é€‰
process_data(
    table_name="sales",
    operation="filter",
    condition="order_date >= '2024-01-01' AND order_date < '2024-02-01'"
)

# ç­›é€‰å‰Næ¡è®°å½•
process_data(
    table_name="sales",
    operation="limit",
    limit=100
)
```

#### æ•°æ®èšåˆ

```python
# æŒ‰ç±»åˆ«èšåˆé”€å”®æ•°æ®
process_data(
    table_name="sales",
    operation="aggregate",
    group_by=["category"],
    aggregations={
        "amount": ["sum", "avg", "count"],
        "quantity": ["sum", "max"]
    }
)

# æŒ‰æ—¥æœŸèšåˆ
process_data(
    table_name="sales",
    operation="aggregate",
    group_by=["DATE(order_date)"],
    aggregations={
        "amount": ["sum"],
        "order_id": ["count"]
    }
)
```

### 5. æ•°æ®å¯¼å‡ºåŠŸèƒ½

#### Excelå¯¼å‡º

```python
# å¯¼å‡ºå®Œæ•´è¡¨æ ¼åˆ°Excel
export_data(
    table_name="sales",
    export_format="excel",
    file_path="reports/sales_report.xlsx"
)

# å¯¼å‡ºæŸ¥è¯¢ç»“æœåˆ°Excel
export_data(
    query="SELECT * FROM sales WHERE amount > 1000",
    export_format="excel",
    file_path="reports/high_value_sales.xlsx",
    sheet_name="é«˜ä»·å€¼é”€å”®"
)

# å¯¼å‡ºå¤šä¸ªå·¥ä½œè¡¨
export_data(
    tables={
        "é”€å”®æ•°æ®": "sales",
        "å®¢æˆ·æ•°æ®": "customers",
        "äº§å“æ•°æ®": "products"
    },
    export_format="excel",
    file_path="reports/complete_report.xlsx"
)
```

#### CSVå¯¼å‡º

```python
# å¯¼å‡ºä¸ºCSVæ–‡ä»¶
export_data(
    table_name="customers",
    export_format="csv",
    file_path="exports/customers.csv",
    encoding="utf-8"  # æŒ‡å®šç¼–ç 
)

# å¯¼å‡ºæŸ¥è¯¢ç»“æœä¸ºCSV
export_data(
    query="""
        SELECT customer_id, name, email, total_orders
        FROM customers 
        WHERE total_orders > 5
        ORDER BY total_orders DESC
    """,
    export_format="csv",
    file_path="exports/vip_customers.csv"
)
```

#### JSONå¯¼å‡º

```python
# å¯¼å‡ºä¸ºJSONæ ¼å¼
export_data(
    table_name="products",
    export_format="json",
    file_path="exports/products.json"
)

# å¯¼å‡ºåµŒå¥—JSONç»“æ„
export_data(
    query="""
        SELECT 
            category,
            JSON_GROUP_ARRAY(
                JSON_OBJECT(
                    'name', name,
                    'price', price,
                    'stock', stock
                )
            ) as products
        FROM products 
        GROUP BY category
    """,
    export_format="json",
    file_path="exports/products_by_category.json"
)
```

#### æ•°æ®ä¿¡æ¯æŸ¥è¯¢

```python
# æŸ¥çœ‹è¡¨ç»“æ„
get_data_info(
    table_name="sales",
    info_type="schema"
)

# æŸ¥çœ‹æ•°æ®æ ·æœ¬
get_data_info(
    table_name="customers",
    info_type="sample",
    limit=10
)

# æŸ¥çœ‹è¡¨ç»Ÿè®¡ä¿¡æ¯
get_data_info(
    table_name="sales",
    info_type="stats"
)

# åˆ—å‡ºæ‰€æœ‰è¡¨
get_data_info(info_type="tables")
```

### 6. æœ€ä½³å®è·µ

#### æ•°æ®å¯¼å…¥æœ€ä½³å®è·µ

```python
# 1. å¤§æ–‡ä»¶åˆ†æ‰¹å¯¼å…¥
connect_data_source(
    source_type="csv",
    config={
        "file_path": "large_dataset.csv",
        "chunk_size": 10000,  # åˆ†æ‰¹å¤„ç†
        "encoding": "utf-8"
    },
    target_table="large_data"
)

# 2. æ•°æ®éªŒè¯å¯¼å…¥
connect_data_source(
    source_type="excel",
    config={
        "file_path": "sales.xlsx",
        "validate_schema": True,  # éªŒè¯æ•°æ®ç»“æ„
        "skip_errors": False     # é‡åˆ°é”™è¯¯åœæ­¢
    },
    target_table="sales"
)
```

#### æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

```python
# 1. ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
execute_sql("""
    CREATE INDEX idx_sales_date ON sales(order_date);
    CREATE INDEX idx_sales_customer ON sales(customer_id);
""")

# 2. åˆ†é¡µæŸ¥è¯¢å¤§æ•°æ®é›†
execute_sql("""
    SELECT * FROM sales 
    ORDER BY order_date DESC 
    LIMIT 1000 OFFSET 0
""")

# 3. ä½¿ç”¨èšåˆå‡å°‘æ•°æ®ä¼ è¾“
execute_sql("""
    SELECT 
        DATE(order_date) as date,
        COUNT(*) as orders,
        SUM(amount) as revenue
    FROM sales 
    WHERE order_date >= '2024-01-01'
    GROUP BY DATE(order_date)
""")
```

#### æ•°æ®å®‰å…¨å®è·µ

```python
# 1. ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯
connect_data_source(
    source_type="mysql",
    config={
        "host": "${DB_HOST}",
        "database": "${DB_NAME}",
        "username": "${DB_USER}",
        "password": "${DB_PASSWORD}"
    }
)

# 2. é™åˆ¶æŸ¥è¯¢ç»“æœæ•°é‡
execute_sql(
    "SELECT * FROM sensitive_data",
    limit=100  # è‡ªåŠ¨æ·»åŠ LIMIT
)

# 3. æ•°æ®è„±æ•å¤„ç†
execute_sql("""
    SELECT 
        customer_id,
        SUBSTR(email, 1, 3) || '***@' || SUBSTR(email, INSTR(email, '@')+1) as masked_email,
        amount
    FROM customers
""")
```

#### é”™è¯¯å¤„ç†å’Œæ—¥å¿—

```python
# 1. å¸¦é”™è¯¯å¤„ç†çš„æ•°æ®å¯¼å…¥
try:
    connect_data_source(
        source_type="csv",
        config={"file_path": "data.csv"},
        target_table="import_data"
    )
except Exception as e:
    print(f"å¯¼å…¥å¤±è´¥: {e}")
    # è®°å½•é”™è¯¯æ—¥å¿—

# 2. æŸ¥è¯¢ç»“æœéªŒè¯
result = execute_sql("SELECT COUNT(*) FROM sales")
if result and len(result) > 0:
    print(f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(result)} æ¡è®°å½•")
else:
    print("æŸ¥è¯¢æ— ç»“æœ")
```

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### API æ•°æ®è·å–

#### é…ç½® API
```python
# æ·»åŠ  API é…ç½®
manage_api_config(
    action="add",
    api_name="weather_api",
    config_data={
        "base_url": "https://api.openweathermap.org/data/2.5",
        "auth_type": "api_key",
        "auth_config": {
            "api_key": "your_api_key",
            "key_param": "appid",
            "key_location": "query"
        },
        "endpoints": {
            "current_weather": {
                "path": "/weather",
                "method": "GET"
            }
        }
    }
)
```

#### è·å– API æ•°æ®
```python
# è·å–å¤©æ°”æ•°æ®
fetch_api_data(
    api_name="weather_api",
    endpoint_name="current_weather",
    params={"q": "Beijing", "units": "metric"}
)
```

### æ•°æ®åº“ç®¡ç†

```python
# åˆ—å‡ºæ‰€æœ‰æ•°æ®æº
list_data_sources()

# è·å–è¡¨ä¿¡æ¯
get_data_info(info_type="tables")

# è·å–è¡¨ç»“æ„
get_data_info(info_type="schema", table_name="sales")

# è·å–ç»Ÿè®¡ä¿¡æ¯
get_data_info(info_type="stats", table_name="sales")

# æ•°æ®åº“è¿æ¥æ± ç®¡ç†
manage_database_config(
    action="optimize",
    config={
        "max_connections": 10,
        "connection_timeout": 30,
        "retry_attempts": 3
    }
)

# æ•°æ®åº“å¤‡ä»½
manage_database_config(
    action="backup",
    config={
        "database_name": "my_mysql",
        "backup_path": "backups/",
        "include_data": True
    }
)
```

### è‡ªåŠ¨åŒ–å·¥ä½œæµ

```python
# å®šä¹‰æ•°æ®å¤„ç†æµæ°´çº¿
def daily_sales_report():
    # 1. å¯¼å…¥æœ€æ–°æ•°æ®
    connect_data_source(
        source_type="csv",
        config={"file_path": "daily_sales.csv"},
        target_table="daily_sales"
    )
    
    # 2. æ•°æ®æ¸…æ´—
    process_data(
        table_name="daily_sales",
        operation="remove_duplicates"
    )
    
    # 3. ç”ŸæˆæŠ¥å‘Š
    report_data = execute_sql("""
        SELECT 
            category,
            SUM(amount) as total_sales,
            COUNT(*) as order_count
        FROM daily_sales
        GROUP BY category
        ORDER BY total_sales DESC
    """)
    
    # 4. å¯¼å‡ºæŠ¥å‘Š
    export_data(
        query="SELECT * FROM daily_sales",
        export_format="excel",
        file_path=f"reports/daily_report_{datetime.now().strftime('%Y%m%d')}.xlsx"
    )
    
    return report_data

# æ‰§è¡Œå·¥ä½œæµ
daily_report = daily_sales_report()
```

---

## ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§

- **SQLæ³¨å…¥é˜²æŠ¤** - è‡ªåŠ¨å‚æ•°åŒ–æŸ¥è¯¢
- **å±é™©æ“ä½œæ‹¦æˆª** - é˜»æ­¢ DROPã€DELETE ç­‰å±é™©æ“ä½œ
- **æŸ¥è¯¢ç»“æœé™åˆ¶** - è‡ªåŠ¨æ·»åŠ  LIMIT é˜²æ­¢å¤§é‡æ•°æ®è¿”å›
- **å‚æ•°éªŒè¯** - ä¸¥æ ¼çš„è¾“å…¥å‚æ•°éªŒè¯
- **ç¯å¢ƒå˜é‡ç®¡ç†** - æ•æ„Ÿä¿¡æ¯é€šè¿‡ç¯å¢ƒå˜é‡ç®¡ç†

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### å®‰å…¨æ€§æ³¨æ„äº‹é¡¹

- **æ•æ„Ÿæ•°æ®ä¿æŠ¤**ï¼šä¸è¦åœ¨é…ç½®æ–‡ä»¶ä¸­ç›´æ¥å­˜å‚¨å¯†ç ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
- **è®¿é—®æƒé™æ§åˆ¶**ï¼šä¸ºæ•°æ®åº“ç”¨æˆ·è®¾ç½®æœ€å°å¿…è¦æƒé™
- **æ•°æ®å¤‡ä»½**ï¼šå®šæœŸå¤‡ä»½é‡è¦æ•°æ®ï¼Œé¿å…æ•°æ®ä¸¢å¤±
- **ç½‘ç»œå®‰å…¨**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨SSL/TLSåŠ å¯†è¿æ¥

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

- **å¤§æ–‡ä»¶å¤„ç†**ï¼šå¯¹äºå¤§å‹CSV/Excelæ–‡ä»¶ï¼Œå»ºè®®åˆ†æ‰¹å¯¼å…¥
- **æŸ¥è¯¢ä¼˜åŒ–**ï¼šä½¿ç”¨é€‚å½“çš„ç´¢å¼•å’ŒLIMITå­å¥
- **å†…å­˜ç®¡ç†**ï¼šé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤§çš„æ•°æ®é›†
- **è¿æ¥æ± **ï¼šåˆç†é…ç½®æ•°æ®åº“è¿æ¥æ± å‚æ•°

### æ•°æ®è´¨é‡ä¿è¯

- **æ•°æ®éªŒè¯**ï¼šå¯¼å…¥å‰æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå®Œæ•´æ€§
- **ç¼–ç å¤„ç†**ï¼šç¡®ä¿æ–‡ä»¶ç¼–ç æ­£ç¡®ï¼ˆæ¨èUTF-8ï¼‰
- **ç±»å‹åŒ¹é…**ï¼šæ³¨æ„æ•°æ®ç±»å‹çš„ä¸€è‡´æ€§
- **å¼‚å¸¸å¤„ç†**ï¼šå»ºç«‹å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶

---

## â“ å¸¸è§é—®é¢˜è§£å†³

### å®‰è£…å’Œé…ç½®é—®é¢˜

**Q: pipå®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**
```bash
# è§£å†³æ–¹æ¡ˆï¼š
# 1. æ›´æ–°pip
pip install --upgrade pip

# 2. ä½¿ç”¨å›½å†…é•œåƒæº
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/ datamaster-mcp

# 3. æ¸…é™¤ç¼“å­˜é‡è¯•
pip cache purge
pip install datamaster-mcp
```

**Q: Claude Desktopæ— æ³•è¯†åˆ«MCPæœåŠ¡å™¨ï¼Ÿ**
```json
è§£å†³æ­¥éª¤ï¼š
1. æ£€æŸ¥é…ç½®æ–‡ä»¶ä½ç½®æ˜¯å¦æ­£ç¡®
2. éªŒè¯JSONæ ¼å¼æ˜¯å¦æœ‰æ•ˆ
3. ç¡®è®¤Pythonè·¯å¾„æ­£ç¡®
4. é‡å¯Claude Desktop
5. æŸ¥çœ‹Claude Desktopæ—¥å¿—
```

**Q: é…ç½®æ–‡ä»¶åœ¨å“ªé‡Œï¼Ÿ**
```
Windows: %APPDATA%\Claude\claude_desktop_config.json
macOS: ~/Library/Application Support/Claude/claude_desktop_config.json
Linux: ~/.config/claude/claude_desktop_config.json
```

### æ•°æ®è¿æ¥é—®é¢˜

**Q: æ— æ³•è¿æ¥åˆ°æ•°æ®åº“ï¼Ÿ**
```python
# è§£å†³æ–¹æ¡ˆï¼š
# 1. æµ‹è¯•è¿æ¥
manage_database_config(
    action="test",
    config={"database_name": "my_db"}
)

# 2. æ£€æŸ¥é…ç½®
# - ä¸»æœºåœ°å€å’Œç«¯å£
# - ç”¨æˆ·åå’Œå¯†ç 
# - æ•°æ®åº“åç§°
# - ç½‘ç»œè¿æ¥

# 3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
# æ£€æŸ¥å…·ä½“çš„é”™è¯¯ä¿¡æ¯
```

**Q: APIè¿æ¥å¤±è´¥ï¼Ÿ**
```python
# è§£å†³æ–¹æ¡ˆï¼š
# 1. éªŒè¯APIå¯†é’¥
# 2. æ£€æŸ¥ç½‘ç»œè¿æ¥
# 3. ç¡®è®¤APIç«¯ç‚¹æ­£ç¡®
# 4. æŸ¥çœ‹APIé™åˆ¶å’Œé…é¢

# æµ‹è¯•APIè¿æ¥
get_api_endpoints(
    api_name="your_api",
    endpoint="/test"
)
```

### æ•°æ®å¤„ç†é—®é¢˜

**Q: å¯¼å…¥çš„æ•°æ®ä¹±ç ï¼Ÿ**
```python
# è§£å†³æ–¹æ¡ˆï¼š
connect_data_source(
    source_type="csv",
    config={
        "file_path": "data.csv",
        "encoding": "utf-8"  # æˆ– "gbk", "gb2312"
    },
    target_table="data"
)
```

**Q: Excelæ–‡ä»¶å¯¼å…¥å¤±è´¥ï¼Ÿ**
```python
# è§£å†³æ–¹æ¡ˆï¼š
# 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸå
# 2. ç¡®è®¤å·¥ä½œè¡¨åç§°
# 3. å¤„ç†åˆå¹¶å•å…ƒæ ¼

connect_data_source(
    source_type="excel",
    config={
        "file_path": "data.xlsx",
        "sheet_name": "Sheet1",  # æŒ‡å®šå·¥ä½œè¡¨
        "header_row": 0         # æŒ‡å®šæ ‡é¢˜è¡Œ
    },
    target_table="data"
)
```

**Q: æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Ÿ**
```sql
-- è§£å†³æ–¹æ¡ˆï¼š
-- 1. æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
SELECT name FROM sqlite_master WHERE type='table';

-- 2. æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
SELECT COUNT(*) FROM your_table;

-- 3. éªŒè¯æŸ¥è¯¢æ¡ä»¶
SELECT * FROM your_table LIMIT 5;
```

### æ€§èƒ½é—®é¢˜

**Q: æŸ¥è¯¢é€Ÿåº¦å¾ˆæ…¢ï¼Ÿ**
```sql
-- è§£å†³æ–¹æ¡ˆï¼š
-- 1. æ·»åŠ ç´¢å¼•
CREATE INDEX idx_column ON table_name(column_name);

-- 2. ä½¿ç”¨LIMITé™åˆ¶ç»“æœ
SELECT * FROM large_table LIMIT 1000;

-- 3. ä¼˜åŒ–æŸ¥è¯¢æ¡ä»¶
SELECT * FROM table WHERE indexed_column = 'value';
```

**Q: å†…å­˜ä¸è¶³ï¼Ÿ**
```python
# è§£å†³æ–¹æ¡ˆï¼š
# 1. åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶
connect_data_source(
    source_type="csv",
    config={
        "file_path": "large_file.csv",
        "chunk_size": 10000  # åˆ†æ‰¹å¤„ç†
    },
    target_table="data"
)

# 2. ä½¿ç”¨æµå¼æŸ¥è¯¢
query_data(
    "SELECT * FROM large_table",
    stream=True,
    batch_size=1000
)
```

### é”™è¯¯ä»£ç è¯´æ˜

| é”™è¯¯ä»£ç  | è¯´æ˜ | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|
| DB_001 | æ•°æ®åº“è¿æ¥å¤±è´¥ | æ£€æŸ¥è¿æ¥å‚æ•°å’Œç½‘ç»œ |
| DB_002 | è®¤è¯å¤±è´¥ | éªŒè¯ç”¨æˆ·åå’Œå¯†ç  |
| API_001 | APIå¯†é’¥æ— æ•ˆ | æ£€æŸ¥APIå¯†é’¥é…ç½® |
| API_002 | APIé™åˆ¶è¶…å‡º | ç­‰å¾…æˆ–å‡çº§APIè®¡åˆ’ |
| FILE_001 | æ–‡ä»¶ä¸å­˜åœ¨ | æ£€æŸ¥æ–‡ä»¶è·¯å¾„ |
| FILE_002 | æ–‡ä»¶æ ¼å¼é”™è¯¯ | ç¡®è®¤æ–‡ä»¶æ ¼å¼å’Œç¼–ç  |

### è·å–å¸®åŠ©

å¦‚æœé‡åˆ°å…¶ä»–é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**ï¼šæ£€æŸ¥è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
2. **æ–‡æ¡£å‚è€ƒ**ï¼šæŸ¥é˜…å®Œæ•´çš„APIæ–‡æ¡£
3. **ç¤¾åŒºæ”¯æŒ**ï¼šåœ¨GitHub Issuesä¸­æé—®
4. **è”ç³»æ”¯æŒ**ï¼šå‘é€é‚®ä»¶è·å–æŠ€æœ¯æ”¯æŒ

---

---

## ğŸ“ è·å–å¸®åŠ©

### æ–‡æ¡£èµ„æº
- ğŸ› ï¸ [å¼€å‘è€…æ–‡æ¡£](å¼€å‘è€…æ–‡æ¡£.md) - æŠ€æœ¯æ–‡æ¡£
- ğŸ“ [é¡¹ç›®ç»“æ„è¯´æ˜](é¡¹ç›®ç»“æ„è¯´æ˜.md) - æ–‡ä»¶ç»„ç»‡
- ğŸ”„ [æ›´æ–°æ—¥å¿—](CHANGELOG.md) - ç‰ˆæœ¬æ›´æ–°è®°å½•

### æ”¯æŒæ¸ é“
- ğŸ› [GitHub Issues](https://github.com/szqshan/DataMaster/issues) - æŠ¥å‘Šé—®é¢˜
- ğŸ’¬ [è®¨è®ºåŒº](https://github.com/szqshan/DataMaster/discussions) - äº¤æµè®¨è®º
- ğŸ“§ é‚®ä»¶æ”¯æŒ - å‘é€é‚®ä»¶è·å–å¸®åŠ©

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

ç°åœ¨ä½ å·²ç»æŒæ¡äº† DataMaster MCP çš„å®Œæ•´ä½¿ç”¨æ–¹æ³•ï¼

**å¿«é€Ÿå¼€å§‹æ­¥éª¤ï¼š**
1. âœ… å®‰è£…ï¼š`pip install datamaster-mcp`
2. âœ… é…ç½®ï¼šæ·»åŠ åˆ° Claude Desktop é…ç½®æ–‡ä»¶
3. âœ… é‡å¯ï¼šé‡å¯ Claude Desktop
4. âœ… æµ‹è¯•ï¼š"è¯·å¸®æˆ‘è¿æ¥ä¸€ä¸ªæ•°æ®æº"
5. âœ… ä½¿ç”¨ï¼šå¼€å§‹ä½ çš„æ•°æ®åˆ†æä¹‹æ—…ï¼

**è®°ä½ï¼šå·¥å…·ä¸“æ³¨æ•°æ®è·å–å’Œè®¡ç®—ï¼ŒAIä¸“æ³¨æ™ºèƒ½åˆ†æå’Œæ´å¯Ÿï¼**

---

**ç‰ˆæœ¬**: v1.0.2 | **çŠ¶æ€**: âœ… ç¨³å®šç‰ˆ | **æ›´æ–°**: 2025-01-24