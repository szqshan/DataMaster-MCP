#!/usr/bin/env python3
"""
DataMaster MCP - è¶…çº§æ•°æ®åˆ†æå·¥å…·
ä¸ºAIæä¾›å¼ºå¤§çš„æ•°æ®åˆ†æèƒ½åŠ›

æ ¸å¿ƒç†å¿µï¼šå·¥å…·ä¸“æ³¨æ•°æ®è·å–å’Œè®¡ç®—ï¼ŒAIä¸“æ³¨æ™ºèƒ½åˆ†æå’Œæ´å¯Ÿ

æ¨¡å—åŒ–æ¶æ„ï¼š
- core/database.py: æ•°æ®åº“ç®¡ç†å’Œè¿æ¥
- core/data_analysis.py: æ•°æ®åˆ†æå’Œç»Ÿè®¡
- core/data_processing.py: æ•°æ®å¤„ç†å’Œå¯¼å‡º
- core/api_manager.py: APIç®¡ç†å’Œæ•°æ®è·å–
"""

import json
import logging
from pathlib import Path
from mcp.server.fastmcp import FastMCP

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("DataMaster_MCP")

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from .core.database import (
        connect_data_source_impl,
        execute_sql_impl,
        query_external_database_impl,
        list_data_sources_impl,
        manage_database_config_impl,
        init_database_module
    )
    from .core.data_analysis import (
        analyze_data_impl,
        get_data_info_impl,
        init_data_analysis_module
    )
    from .core.data_processing import (
        process_data_impl,
        export_data_impl,
        init_data_processing_module
    )
    from .core.api_manager import (
        manage_api_config_impl,
        fetch_api_data_impl,
        api_data_preview_impl,
        create_api_storage_session_impl,
        list_api_storage_sessions_impl,
        init_api_manager_module
    )
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    import sys
    current_dir = Path(__file__).parent.parent
    if str(current_dir) not in sys.path:
        sys.path.insert(0, str(current_dir))
    
    from datamaster_mcp.core.database import (
        connect_data_source_impl,
        execute_sql_impl,
        query_external_database_impl,
        list_data_sources_impl,
        manage_database_config_impl,
        init_database_module
    )
    from datamaster_mcp.core.data_analysis import (
        analyze_data_impl,
        get_data_info_impl,
        init_data_analysis_module
    )
    from datamaster_mcp.core.data_processing import (
        process_data_impl,
        export_data_impl,
        init_data_processing_module
    )
    from datamaster_mcp.core.api_manager import (
        manage_api_config_impl,
        fetch_api_data_impl,
        api_data_preview_impl,
        create_api_storage_session_impl,
        list_api_storage_sessions_impl,
        init_api_manager_module
    )

# ================================
# é…ç½®å’Œåˆå§‹åŒ–
# ================================
TOOL_NAME = "DataMaster_MCP"
DATA_DIR = "data"
EXPORTS_DIR = "exports"

# åˆ›å»ºMCPæœåŠ¡å™¨
mcp = FastMCP(TOOL_NAME)

# ç¡®ä¿ç›®å½•å­˜åœ¨
for directory in [DATA_DIR, EXPORTS_DIR]:
    Path(directory).mkdir(exist_ok=True)

# åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒæ¨¡å—
try:
    init_database_module()
    init_data_analysis_module()
    init_data_processing_module()
    init_api_manager_module()
    logger.info("æ‰€æœ‰æ ¸å¿ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    logger.error(f"æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")

# ================================
# æ•°æ®åº“ç®¡ç†å·¥å…·
# ================================

@mcp.tool()
def connect_data_source(
    source_type: str,
    config: dict,
    target_table: str = None,
    target_database: str = None
) -> str:
    """
    ğŸ”— æ•°æ®æºè¿æ¥è·¯ç”±å™¨ - AIå¿…è¯»ä½¿ç”¨æŒ‡å—
    
    âš ï¸ é‡è¦ï¼šæ•°æ®åº“è¿æ¥é‡‡ç”¨"ä¸¤æ­¥è¿æ¥æ³•"è®¾è®¡æ¨¡å¼ï¼
    
    ğŸ“‹ æ”¯æŒçš„æ•°æ®æºç±»å‹ï¼š
    - "excel" - Excelæ–‡ä»¶å¯¼å…¥åˆ°æ•°æ®åº“
    - "csv" - CSVæ–‡ä»¶å¯¼å…¥åˆ°æ•°æ®åº“
    - "json" - JSONæ–‡ä»¶å¯¼å…¥åˆ°æ•°æ®åº“ï¼ˆæ”¯æŒåµŒå¥—ç»“æ„è‡ªåŠ¨æ‰å¹³åŒ–ï¼‰
    - "sqlite" - SQLiteæ•°æ®åº“æ–‡ä»¶è¿æ¥
    - "mysql" - MySQLæ•°æ®åº“è¿æ¥ï¼ˆç¬¬ä¸€æ­¥ï¼šåˆ›å»ºä¸´æ—¶é…ç½®ï¼‰
    - "postgresql" - PostgreSQLæ•°æ®åº“è¿æ¥ï¼ˆç¬¬ä¸€æ­¥ï¼šåˆ›å»ºä¸´æ—¶é…ç½®ï¼‰
    - "mongodb" - MongoDBæ•°æ®åº“è¿æ¥ï¼ˆç¬¬ä¸€æ­¥ï¼šåˆ›å»ºä¸´æ—¶é…ç½®ï¼‰
    - "database_config" - ä½¿ç”¨å·²æœ‰é…ç½®è¿æ¥ï¼ˆç¬¬äºŒæ­¥ï¼šå®é™…è¿æ¥ï¼‰
    
    ğŸ¯ AIä½¿ç”¨æµç¨‹ï¼š
    1ï¸âƒ£ æ•°æ®åº“è¿æ¥ç¬¬ä¸€æ­¥ï¼š
       connect_data_source(source_type="mysql", config={host, port, user, database, password})
       â†’ è¿”å›ä¸´æ—¶é…ç½®åç§°ï¼ˆå¦‚ï¼štemp_mysql_20250724_173102ï¼‰
    
    2ï¸âƒ£ æ•°æ®åº“è¿æ¥ç¬¬äºŒæ­¥ï¼š
       connect_data_source(source_type="database_config", config={"database_name": "é…ç½®åç§°"})
       â†’ å»ºç«‹å¯æŸ¥è¯¢çš„æ•°æ®åº“è¿æ¥
    
    3ï¸âƒ£ æŸ¥è¯¢æ•°æ®ï¼š
       ä½¿ç”¨ query_external_database(database_name="é…ç½®åç§°", query="SQL")
    
    ğŸ’¡ å‚æ•°å…¼å®¹æ€§ï¼š
    - æ”¯æŒ "user" æˆ– "username" å‚æ•°
    - ç«¯å£å·ä½¿ç”¨æ•°å­—ç±»å‹ï¼ˆå¦‚ï¼š3306ï¼‰
    - å¯†ç ä½¿ç”¨å­—ç¬¦ä¸²ç±»å‹
    
    Args:
        source_type: æ•°æ®æºç±»å‹ï¼Œå¿…é¡»æ˜¯ä¸Šè¿°æ”¯æŒçš„ç±»å‹ä¹‹ä¸€
        config: é…ç½®å‚æ•°å­—å…¸ï¼Œæ ¼å¼æ ¹æ®source_typeä¸åŒ
        target_table: ç›®æ ‡è¡¨åï¼ˆæ–‡ä»¶å¯¼å…¥æ—¶å¯é€‰ï¼‰
        target_database: ç›®æ ‡æ•°æ®åº“åç§°ï¼ˆæ–‡ä»¶å¯¼å…¥åˆ°å¤–éƒ¨æ•°æ®åº“æ—¶å¯é€‰ï¼‰
    
    Returns:
        str: JSONæ ¼å¼çš„è¿æ¥ç»“æœï¼ŒåŒ…å«çŠ¶æ€ã€æ¶ˆæ¯å’Œé…ç½®ä¿¡æ¯
    
    âš¡ AIå¿«é€Ÿä¸Šæ‰‹ï¼š
    è®°ä½"ä¸¤æ­¥è¿æ¥æ³•"ï¼šå…ˆåˆ›å»ºé…ç½® â†’ å†ä½¿ç”¨é…ç½® â†’ æœ€åæŸ¥è¯¢æ•°æ®
    """
    return connect_data_source_impl(source_type, config, target_table, target_database)

@mcp.tool()
def execute_sql(
    query: str,
    params: dict = None,
    limit: int = 1000,
    data_source: str = None
) -> str:
    """
    ğŸ“Š SQLæ‰§è¡Œå·¥å…· - æœ¬åœ°æ•°æ®åº“æŸ¥è¯¢ä¸“ç”¨
    
    ğŸ¯ ä½¿ç”¨åœºæ™¯ï¼š
    - æŸ¥è¯¢æœ¬åœ°SQLiteæ•°æ®åº“ï¼ˆé»˜è®¤ï¼‰
    - æŸ¥è¯¢å·²å¯¼å…¥çš„Excel/CSVæ•°æ®
    - æŸ¥è¯¢æŒ‡å®šçš„æœ¬åœ°æ•°æ®æº
    
    âš ï¸ é‡è¦åŒºåˆ«ï¼š
    - æœ¬åœ°æ•°æ®æŸ¥è¯¢ â†’ ä½¿ç”¨æ­¤å·¥å…· (execute_sql)
    - å¤–éƒ¨æ•°æ®åº“æŸ¥è¯¢ â†’ ä½¿ç”¨ query_external_database
    
    ğŸ”’ å®‰å…¨ç‰¹æ€§ï¼š
    - è‡ªåŠ¨æ·»åŠ LIMITé™åˆ¶é˜²æ­¢å¤§é‡æ•°æ®è¿”å›
    - æ”¯æŒå‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢SQLæ³¨å…¥
    - åªå…è®¸SELECTæŸ¥è¯¢ï¼Œæ‹’ç»å±é™©æ“ä½œ
    
    Args:
        query: SQLæŸ¥è¯¢è¯­å¥ï¼ˆæ¨èä½¿ç”¨SELECTè¯­å¥ï¼‰
        params: æŸ¥è¯¢å‚æ•°å­—å…¸ï¼Œç”¨äºå‚æ•°åŒ–æŸ¥è¯¢ï¼ˆå¯é€‰ï¼‰
        limit: ç»“æœè¡Œæ•°é™åˆ¶ï¼Œé»˜è®¤1000è¡Œï¼ˆå¯é€‰ï¼‰
        data_source: æ•°æ®æºåç§°ï¼Œé»˜è®¤æœ¬åœ°SQLiteï¼ˆå¯é€‰ï¼‰
    
    Returns:
        str: JSONæ ¼å¼æŸ¥è¯¢ç»“æœï¼ŒåŒ…å«åˆ—åã€æ•°æ®è¡Œå’Œç»Ÿè®¡ä¿¡æ¯
    
    ğŸ’¡ AIä½¿ç”¨æç¤ºï¼š
    - æŸ¥è¯¢æœ¬åœ°æ•°æ®æ—¶ä¼˜å…ˆä½¿ç”¨æ­¤å·¥å…·
    - æŸ¥è¯¢å¤–éƒ¨æ•°æ®åº“æ—¶ä½¿ç”¨ query_external_database
    - ä½¿ç”¨ get_data_info å…ˆäº†è§£è¡¨ç»“æ„
    """
    return execute_sql_impl(query, params, limit, data_source)

@mcp.tool()
def query_external_database(
    database_name: str,
    query: str,
    limit: int = 1000
) -> str:
    """
    ğŸŒ å¤–éƒ¨æ•°æ®åº“æŸ¥è¯¢å·¥å…· - ä¸“é—¨æŸ¥è¯¢å¤–éƒ¨æ•°æ®åº“
    
    ğŸ¯ ä½¿ç”¨åœºæ™¯ï¼š
    - æŸ¥è¯¢MySQLæ•°æ®åº“
    - æŸ¥è¯¢PostgreSQLæ•°æ®åº“
    - æŸ¥è¯¢MongoDBæ•°æ®åº“
    - æŸ¥è¯¢æ‰€æœ‰é€šè¿‡connect_data_sourceè¿æ¥çš„å¤–éƒ¨æ•°æ®åº“
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼š
    å¿…é¡»å…ˆä½¿ç”¨connect_data_sourceå»ºç«‹æ•°æ®åº“è¿æ¥å¹¶è·å¾—é…ç½®åç§°
    
    ğŸ”„ å®Œæ•´æµç¨‹ç¤ºä¾‹ï¼š
    1ï¸âƒ£ connect_data_source(source_type="mysql", config={...}) â†’ è·å¾—é…ç½®å
    2ï¸âƒ£ connect_data_source(source_type="database_config", config={"database_name": "é…ç½®å"}) â†’ å»ºç«‹è¿æ¥
    3ï¸âƒ£ query_external_database(database_name="é…ç½®å", query="SELECT * FROM table") â†’ æŸ¥è¯¢æ•°æ®
    
    ğŸ’¡ æŸ¥è¯¢è¯­æ³•æ”¯æŒï¼š
    - MySQL/PostgreSQL: æ ‡å‡†SQLè¯­æ³•
    - MongoDB: æ”¯æŒå¤šç§æŸ¥è¯¢æ ¼å¼ï¼ˆJSONã€JavaScripté£æ ¼ç­‰ï¼‰
    
    Args:
        database_name: æ•°æ®åº“é…ç½®åç§°ï¼ˆä»connect_data_sourceè·å¾—ï¼‰
        query: æŸ¥è¯¢è¯­å¥ï¼ŒSQLæˆ–MongoDBæŸ¥è¯¢è¯­æ³•
        limit: ç»“æœè¡Œæ•°é™åˆ¶ï¼Œé»˜è®¤1000è¡Œ
    
    Returns:
        str: JSONæ ¼å¼æŸ¥è¯¢ç»“æœï¼ŒåŒ…å«æ•°æ®è¡Œã€ç»Ÿè®¡ä¿¡æ¯å’Œå…ƒæ•°æ®
    
    ğŸš€ AIä½¿ç”¨å»ºè®®ï¼š
    - è¿™æ˜¯æŸ¥è¯¢å¤–éƒ¨æ•°æ®åº“çš„é¦–é€‰å·¥å…·
    - ä½¿ç”¨list_data_sourcesæŸ¥çœ‹å¯ç”¨çš„æ•°æ®åº“é…ç½®
    - é…ç½®åç§°é€šå¸¸æ ¼å¼ä¸ºï¼štemp_mysql_20250724_173102
    """
    return query_external_database_impl(database_name, query, limit)

@mcp.tool()
def list_data_sources() -> str:
    """
    ğŸ“‹ æ•°æ®æºåˆ—è¡¨å·¥å…· - æŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„æ•°æ®æº
    
    ğŸ¯ åŠŸèƒ½è¯´æ˜ï¼š
    - æ˜¾ç¤ºæœ¬åœ°SQLiteæ•°æ®åº“çŠ¶æ€
    - åˆ—å‡ºæ‰€æœ‰å¤–éƒ¨æ•°æ®åº“é…ç½®
    - æ˜¾ç¤ºæ¯ä¸ªæ•°æ®æºçš„è¿æ¥çŠ¶æ€å’ŒåŸºæœ¬ä¿¡æ¯
    - åŒºåˆ†ä¸´æ—¶é…ç½®å’Œæ°¸ä¹…é…ç½®
    
    ğŸ“Š è¿”å›ä¿¡æ¯åŒ…æ‹¬ï¼š
    - æ•°æ®æºåç§°å’Œç±»å‹
    - è¿æ¥çŠ¶æ€ï¼ˆå¯ç”¨/å·²é…ç½®/å·²ç¦ç”¨ï¼‰
    - ä¸»æœºåœ°å€å’Œæ•°æ®åº“å
    - æ˜¯å¦ä¸ºé»˜è®¤æ•°æ®æº
    - é…ç½®åˆ›å»ºæ—¶é—´ï¼ˆä¸´æ—¶é…ç½®ï¼‰
    
    ğŸ’¡ ä½¿ç”¨åœºæ™¯ï¼š
    - ä¸ç¡®å®šæœ‰å“ªäº›æ•°æ®æºæ—¶æŸ¥çœ‹
    - æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€
    - æŸ¥æ‰¾ä¸´æ—¶é…ç½®åç§°
    - äº†è§£å¯ç”¨çš„æŸ¥è¯¢ç›®æ ‡
    
    Returns:
        str: JSONæ ¼å¼çš„æ•°æ®æºåˆ—è¡¨ï¼ŒåŒ…å«è¯¦ç»†çš„é…ç½®ä¿¡æ¯
    
    ğŸš€ AIä½¿ç”¨å»ºè®®ï¼š
    - åœ¨æŸ¥è¯¢æ•°æ®å‰å…ˆè°ƒç”¨æ­¤å·¥å…·äº†è§£å¯ç”¨æ•°æ®æº
    - ç”¨äºè·å–æ­£ç¡®çš„database_nameå‚æ•°
    - æ£€æŸ¥ä¸´æ—¶é…ç½®æ˜¯å¦è¿˜å­˜åœ¨
    """
    return list_data_sources_impl()

@mcp.tool()
def manage_database_config(
    action: str,
    config: dict = None
) -> str:
    """
    âš™ï¸ æ•°æ®åº“é…ç½®ç®¡ç†å·¥å…· - ç®¡ç†æ‰€æœ‰æ•°æ®åº“è¿æ¥é…ç½®
    
    ğŸ¯ æ”¯æŒçš„æ“ä½œç±»å‹ï¼š
    - "list" - åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“é…ç½®ï¼ˆåŒ…æ‹¬ä¸´æ—¶å’Œæ°¸ä¹…ï¼‰
    - "test" - æµ‹è¯•æŒ‡å®šé…ç½®çš„è¿æ¥çŠ¶æ€
    - "add" - æ·»åŠ æ°¸ä¹…æ•°æ®åº“é…ç½®
    - "remove" - åˆ é™¤æŒ‡å®šé…ç½®
    - "reload" - é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
    - "list_temp" - ä»…åˆ—å‡ºä¸´æ—¶é…ç½®
    - "cleanup_temp" - æ¸…ç†æ‰€æœ‰ä¸´æ—¶é…ç½®
    
    ğŸ“‹ å¸¸ç”¨æ“ä½œç¤ºä¾‹ï¼š
    
    1ï¸âƒ£ æŸ¥çœ‹æ‰€æœ‰é…ç½®ï¼š
       manage_database_config(action="list")
    
    2ï¸âƒ£ æµ‹è¯•è¿æ¥ï¼š
       manage_database_config(action="test", config={"database_name": "é…ç½®å"})
    
    3ï¸âƒ£ æ·»åŠ æ°¸ä¹…é…ç½®ï¼š
       manage_database_config(action="add", config={
           "database_name": "my_mysql",
           "database_config": {
               "host": "localhost",
               "port": 3306,
               "type": "mysql",
               "user": "root",
               "database": "test_db",
               "password": "password"
           }
       })
    
    4ï¸âƒ£ æ¸…ç†ä¸´æ—¶é…ç½®ï¼š
       manage_database_config(action="cleanup_temp")
    
    Args:
        action: æ“ä½œç±»å‹ï¼Œå¿…é¡»æ˜¯ä¸Šè¿°æ”¯æŒçš„æ“ä½œä¹‹ä¸€
        config: é…ç½®å‚æ•°å­—å…¸ï¼Œæ ¹æ®actionç±»å‹æä¾›ä¸åŒå‚æ•°
    
    Returns:
        str: JSONæ ¼å¼æ“ä½œç»“æœï¼ŒåŒ…å«çŠ¶æ€ã€æ¶ˆæ¯å’Œç›¸å…³æ•°æ®
    
    ğŸ’¡ AIä½¿ç”¨å»ºè®®ï¼š
    - ä¸ç¡®å®šæœ‰å“ªäº›é…ç½®æ—¶ï¼Œå…ˆç”¨action="list"æŸ¥çœ‹
    - è¿æ¥é—®é¢˜æ—¶ï¼Œç”¨action="test"æ£€æŸ¥é…ç½®çŠ¶æ€
    - ä¸´æ—¶é…ç½®è¿‡å¤šæ—¶ï¼Œç”¨action="cleanup_temp"æ¸…ç†
    """
    return manage_database_config_impl(action, config)

# ================================
# æ•°æ®åˆ†æå·¥å…·
# ================================

@mcp.tool()
def get_data_info(
    info_type: str = "tables",
    table_name: str = None,
    data_source: str = None
) -> str:
    """
    ğŸ“Š æ•°æ®ä¿¡æ¯è·å–å·¥å…· - æŸ¥çœ‹æ•°æ®åº“ç»“æ„å’Œç»Ÿè®¡ä¿¡æ¯
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - è·å–æ•°æ®åº“è¡¨åˆ—è¡¨ã€è¡¨ç»“æ„ã€æ•°æ®ç»Ÿè®¡ç­‰ä¿¡æ¯
    - æ”¯æŒæœ¬åœ°SQLiteå’Œå¤–éƒ¨æ•°æ®åº“
    - æä¾›è¯¦ç»†çš„è¡¨ç»“æ„å’Œæ•°æ®æ¦‚è§ˆ
    - æ™ºèƒ½æ•°æ®åº“æ¸…ç†ç®¡ç†åŠŸèƒ½
    
    Args:
        info_type: ä¿¡æ¯ç±»å‹
            - "tables": è·å–æ‰€æœ‰è¡¨/é›†åˆåˆ—è¡¨ï¼ˆé»˜è®¤ï¼‰
            - "schema": è·å–æŒ‡å®šè¡¨çš„ç»“æ„ä¿¡æ¯ï¼ˆéœ€è¦table_nameï¼‰
            - "stats": è·å–æŒ‡å®šè¡¨çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆéœ€è¦table_nameï¼‰
            - "cleanup": æ™ºèƒ½æ£€æµ‹è¿‡æ—¶æ•°æ®å’Œè¡¨ï¼Œæä¾›æ¸…ç†å»ºè®®
        table_name: è¡¨åï¼ˆå½“info_typeä¸ºschemaæˆ–statsæ—¶å¿…éœ€ï¼‰
        data_source: æ•°æ®æºåç§°
            - None: ä½¿ç”¨æœ¬åœ°SQLiteæ•°æ®åº“ï¼ˆé»˜è®¤ï¼‰
            - é…ç½®åç§°: ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“ï¼ˆéœ€å…ˆé€šè¿‡manage_database_configåˆ›å»ºé…ç½®ï¼‰
    
    Returns:
        str: JSONæ ¼å¼çš„æ•°æ®åº“ä¿¡æ¯ï¼ŒåŒ…å«çŠ¶æ€ã€æ•°æ®å’Œå…ƒæ•°æ®
    
    ğŸ¤– AIä½¿ç”¨å»ºè®®ï¼š
    1. æ•°æ®æ¢ç´¢ï¼šå…ˆç”¨info_type="tables"æŸ¥çœ‹æ‰€æœ‰è¡¨
    2. ç»“æ„åˆ†æï¼šç”¨info_type="schema"äº†è§£è¡¨ç»“æ„
    3. æ•°æ®æ¦‚è§ˆï¼šç”¨info_type="stats"è·å–ç»Ÿè®¡ä¿¡æ¯
    4. æ•°æ®åº“ç»´æŠ¤ï¼šç”¨info_type="cleanup"æ£€æµ‹å¹¶æ¸…ç†è¿‡æ—¶æ•°æ®
    5. å¤–éƒ¨æ•°æ®åº“ï¼šç¡®ä¿data_sourceé…ç½®å·²å­˜åœ¨
    
    ğŸ’¡ æœ€ä½³å®è·µï¼š
    - åœ¨æŸ¥è¯¢æ•°æ®å‰å…ˆäº†è§£è¡¨ç»“æ„
    - ä½¿ç”¨statsäº†è§£æ•°æ®åˆ†å¸ƒå’Œè´¨é‡
    - å®šæœŸä½¿ç”¨cleanupåŠŸèƒ½ç»´æŠ¤æ•°æ®åº“æ•´æ´
    - ç»“åˆanalyze_dataå·¥å…·è¿›è¡Œæ·±åº¦åˆ†æ
    
    âš ï¸ å¸¸è§é”™è¯¯é¿å…ï¼š
    - schemaå’Œstatså¿…é¡»æŒ‡å®štable_name
    - å¤–éƒ¨æ•°æ®åº“éœ€è¦æœ‰æ•ˆçš„data_sourceé…ç½®
    - è¡¨ååŒºåˆ†å¤§å°å†™
    - cleanupåŠŸèƒ½ä»…é€‚ç”¨äºæœ¬åœ°SQLiteæ•°æ®åº“
    
    ğŸ“ˆ é«˜æ•ˆä½¿ç”¨æµç¨‹ï¼š
    1. get_data_info(info_type="tables") â†’ æŸ¥çœ‹æ‰€æœ‰è¡¨
    2. get_data_info(info_type="schema", table_name="è¡¨å") â†’ äº†è§£ç»“æ„
    3. get_data_info(info_type="stats", table_name="è¡¨å") â†’ æŸ¥çœ‹ç»Ÿè®¡
    4. get_data_info(info_type="cleanup") â†’ æ£€æµ‹è¿‡æ—¶æ•°æ®
    5. analyze_data() â†’ æ·±åº¦åˆ†æ
    
    ğŸ¯ å…³é”®ç†è§£ç‚¹ï¼š
    - è¿™æ˜¯æ•°æ®æ¢ç´¢çš„ç¬¬ä¸€æ­¥å·¥å…·
    - ä¸ºåç»­åˆ†ææä¾›åŸºç¡€ä¿¡æ¯
    - æ”¯æŒæœ¬åœ°å’Œè¿œç¨‹æ•°æ®æº
    - æ™ºèƒ½ç»´æŠ¤æ•°æ®åº“æ•´æ´æ€§
    
    ğŸ§¹ æ•°æ®åº“æ¸…ç†åŠŸèƒ½ï¼ˆinfo_type="cleanup"ï¼‰ï¼š
    - è‡ªåŠ¨æ£€æµ‹æµ‹è¯•è¡¨ã€ä¸´æ—¶è¡¨ã€è¿‡æ—¶è¡¨
    - è¯†åˆ«ç©ºè¡¨å’Œé‡å¤è¡¨
    - åˆ†æè¡¨çš„åˆ›å»ºæ—¶é—´å’Œæœ€åè®¿é—®æ—¶é—´
    - æä¾›æ™ºèƒ½æ¸…ç†å»ºè®®ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦æ‰§è¡Œæ¸…ç†
    - æ”¯æŒæ‰¹é‡æ¸…ç†å’Œé€‰æ‹©æ€§æ¸…ç†
    """
    return get_data_info_impl(info_type, table_name, data_source)

@mcp.tool()
def analyze_data(
    analysis_type: str,
    table_name: str,
    columns: list = None,
    options: dict = None
) -> str:
    """
    ğŸ” æ•°æ®åˆ†æå·¥å…· - æ‰§è¡Œå„ç§ç»Ÿè®¡åˆ†æå’Œæ•°æ®è´¨é‡æ£€æŸ¥
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - æä¾›5ç§æ ¸å¿ƒæ•°æ®åˆ†æåŠŸèƒ½
    - æ”¯æŒæŒ‡å®šåˆ—åˆ†ææˆ–å…¨è¡¨åˆ†æ
    - è‡ªåŠ¨å¤„ç†æ•°æ®ç±»å‹å’Œç¼ºå¤±å€¼
    - è¿”å›è¯¦ç»†çš„åˆ†æç»“æœå’Œå¯è§†åŒ–å»ºè®®
    
    Args:
        analysis_type: åˆ†æç±»å‹
            - "basic_stats": åŸºç¡€ç»Ÿè®¡åˆ†æï¼ˆå‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®ç­‰ï¼‰
            - "correlation": ç›¸å…³æ€§åˆ†æï¼ˆæ•°å€¼åˆ—ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼‰
            - "outliers": å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆIQRã€Z-scoreæ–¹æ³•ï¼‰
            - "missing_values": ç¼ºå¤±å€¼åˆ†æï¼ˆç¼ºå¤±ç‡ã€åˆ†å¸ƒæ¨¡å¼ï¼‰
            - "duplicates": é‡å¤å€¼æ£€æµ‹ï¼ˆå®Œå…¨é‡å¤ã€éƒ¨åˆ†é‡å¤ï¼‰
        table_name: è¦åˆ†æçš„æ•°æ®è¡¨å
        columns: åˆ†æçš„åˆ—ååˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            - None: åˆ†ææ‰€æœ‰é€‚ç”¨åˆ—
            - ["col1", "col2"]: åªåˆ†ææŒ‡å®šåˆ—
        options: åˆ†æé€‰é¡¹ï¼ˆå¯é€‰å­—å…¸ï¼‰
            - outliers: {"method": "iqr|zscore", "threshold": 1.5}
            - correlation: {"method": "pearson|spearman"}
            - basic_stats: {"percentiles": [25, 50, 75, 90, 95]}
    
    Returns:
        str: JSONæ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«ç»Ÿè®¡æ•°æ®ã€å›¾è¡¨å»ºè®®å’Œæ´å¯Ÿ
    
    ğŸ¤– AIä½¿ç”¨å»ºè®®ï¼š
    1. æ•°æ®æ¦‚è§ˆï¼šå…ˆç”¨"basic_stats"äº†è§£æ•°æ®åˆ†å¸ƒ
    2. è´¨é‡æ£€æŸ¥ï¼šç”¨"missing_values"å’Œ"duplicates"æ£€æŸ¥æ•°æ®è´¨é‡
    3. å…³ç³»æ¢ç´¢ï¼šç”¨"correlation"å‘ç°å˜é‡å…³ç³»
    4. å¼‚å¸¸æ£€æµ‹ï¼šç”¨"outliers"è¯†åˆ«å¼‚å¸¸æ•°æ®
    5. é€æ­¥æ·±å…¥ï¼šä»åŸºç¡€ç»Ÿè®¡åˆ°é«˜çº§åˆ†æ
    
    ğŸ’¡ æœ€ä½³å®è·µï¼š
    - å…ˆè¿›è¡Œbasic_statsäº†è§£æ•°æ®æ¦‚å†µ
    - æ•°å€¼åˆ—ç”¨correlationåˆ†æå…³ç³»
    - å¤§æ•°æ®é›†æŒ‡å®šcolumnsæé«˜æ•ˆç‡
    - ç»“åˆget_data_infoäº†è§£è¡¨ç»“æ„
    
    âš ï¸ å¸¸è§é”™è¯¯é¿å…ï¼š
    - ç¡®ä¿table_nameå­˜åœ¨
    - correlationåªé€‚ç”¨äºæ•°å€¼åˆ—
    - columnsåç§°å¿…é¡»å‡†ç¡®åŒ¹é…
    - ç©ºè¡¨æˆ–å•åˆ—è¡¨æŸäº›åˆ†æä¼šå¤±è´¥
    
    ğŸ“ˆ é«˜æ•ˆä½¿ç”¨æµç¨‹ï¼š
    1. get_data_info() â†’ äº†è§£è¡¨ç»“æ„
    2. analyze_data("basic_stats") â†’ åŸºç¡€ç»Ÿè®¡
    3. analyze_data("missing_values") â†’ è´¨é‡æ£€æŸ¥
    4. analyze_data("correlation") â†’ å…³ç³»åˆ†æ
    5. analyze_data("outliers") â†’ å¼‚å¸¸æ£€æµ‹
    
    ğŸ¯ å…³é”®ç†è§£ç‚¹ï¼š
    - æ¯ç§åˆ†æç±»å‹æœ‰ç‰¹å®šé€‚ç”¨åœºæ™¯
    - ç»“æœåŒ…å«ç»Ÿè®¡æ•°æ®å’Œä¸šåŠ¡æ´å¯Ÿ
    - æ”¯æŒå‚æ•°åŒ–å®šåˆ¶åˆ†æè¡Œä¸º
    """
    return analyze_data_impl(analysis_type, table_name, columns, options)

# ================================
# æ•°æ®å¤„ç†å·¥å…·
# ================================

@mcp.tool()
def process_data(
    operation_type: str,
    data_source: str,
    config: dict,
    target_table: str = None
) -> str:
    """
    âš™ï¸ æ•°æ®å¤„ç†å·¥å…· - æ‰§è¡Œæ•°æ®æ¸…æ´—ã€è½¬æ¢ã€ç­›é€‰ç­‰æ“ä½œ
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - æä¾›6ç§æ ¸å¿ƒæ•°æ®å¤„ç†åŠŸèƒ½
    - æ”¯æŒè¡¨å’ŒSQLæŸ¥è¯¢ä½œä¸ºæ•°æ®æº
    - çµæ´»çš„é…ç½®å‚æ•°ç³»ç»Ÿ
    - å¯æŒ‡å®šç›®æ ‡è¡¨æˆ–è¦†ç›–åŸè¡¨
    
    Args:
        operation_type: å¤„ç†æ“ä½œç±»å‹
            - "clean": æ•°æ®æ¸…æ´—ï¼ˆå»é‡ã€å¡«å……ç¼ºå¤±å€¼ã€æ•°æ®ç±»å‹è½¬æ¢ï¼‰
            - "transform": æ•°æ®è½¬æ¢ï¼ˆåˆ—é‡å‘½åã€æ ‡å‡†åŒ–ã€æ–°åˆ—è®¡ç®—ï¼‰
            - "filter": æ•°æ®ç­›é€‰ï¼ˆæ¡ä»¶è¿‡æ»¤ã€åˆ—é€‰æ‹©ã€æ•°æ®é‡‡æ ·ï¼‰
            - "aggregate": æ•°æ®èšåˆï¼ˆåˆ†ç»„ç»Ÿè®¡ã€æ±‡æ€»è®¡ç®—ï¼‰
            - "merge": æ•°æ®åˆå¹¶ï¼ˆè¡¨è¿æ¥ã€æ•°æ®æ‹¼æ¥ï¼‰
            - "reshape": æ•°æ®é‡å¡‘ï¼ˆé€è§†è¡¨ã€å®½é•¿è½¬æ¢ï¼‰
        data_source: æ•°æ®æº
            - è¡¨å: å¤„ç†æ•´ä¸ªè¡¨
            - SQLæŸ¥è¯¢: å¤„ç†æŸ¥è¯¢ç»“æœ
        config: æ“ä½œé…ç½®å­—å…¸ï¼ˆå¿…éœ€ï¼‰
            - clean: {"remove_duplicates": True, "fill_missing": {"col": {"method": "mean"}}}
            - transform: {"rename_columns": {"old": "new"}, "normalize": {"columns": ["col1"]}}
            - filter: {"filter_condition": "age > 18", "select_columns": ["name", "age"]}
            - aggregate: {"group_by": {"columns": ["dept"], "agg": {"salary": "mean"}}}
            - merge: {"right_table": "table2", "on": "id", "how": "inner"}
            - reshape: {"pivot": {"index": "date", "columns": "product", "values": "sales"}}
        target_table: ç›®æ ‡è¡¨åï¼ˆå¯é€‰ï¼‰
            - None: è¦†ç›–åŸè¡¨ï¼ˆé»˜è®¤ï¼‰
            - è¡¨å: ä¿å­˜åˆ°æ–°è¡¨
    
    Returns:
        str: JSONæ ¼å¼çš„å¤„ç†ç»“æœï¼ŒåŒ…å«æ“ä½œè¯¦æƒ…ã€å½±å“è¡Œæ•°å’Œæ–°è¡¨ä¿¡æ¯
    
    ğŸ¤– AIä½¿ç”¨å»ºè®®ï¼š
    1. æ•°æ®æ¸…æ´—ï¼šå…ˆç”¨"clean"å¤„ç†æ•°æ®è´¨é‡é—®é¢˜
    2. æ•°æ®è½¬æ¢ï¼šç”¨"transform"æ ‡å‡†åŒ–å’Œè®¡ç®—æ–°å­—æ®µ
    3. æ•°æ®ç­›é€‰ï¼šç”¨"filter"è·å–ç›®æ ‡æ•°æ®å­é›†
    4. æ•°æ®èšåˆï¼šç”¨"aggregate"ç”Ÿæˆæ±‡æ€»æŠ¥è¡¨
    5. æ•°æ®åˆå¹¶ï¼šç”¨"merge"å…³è”å¤šä¸ªæ•°æ®æº
    6. æ•°æ®é‡å¡‘ï¼šç”¨"reshape"æ”¹å˜æ•°æ®ç»“æ„
    
    ğŸ’¡ æœ€ä½³å®è·µï¼š
    - å¤„ç†å‰å…ˆå¤‡ä»½é‡è¦æ•°æ®
    - ä½¿ç”¨target_tableé¿å…è¦†ç›–åŸæ•°æ®
    - å¤æ‚æ“ä½œåˆ†æ­¥éª¤æ‰§è¡Œ
    - ç»“åˆanalyze_dataéªŒè¯å¤„ç†ç»“æœ
    
    âš ï¸ å¸¸è§é”™è¯¯é¿å…ï¼š
    - configå‚æ•°å¿…é¡»ç¬¦åˆoperation_typeè¦æ±‚
    - ç¡®ä¿å¼•ç”¨çš„åˆ—åå­˜åœ¨
    - mergeæ“ä½œéœ€è¦ç¡®ä¿å…³è”é”®å­˜åœ¨
    - å¤§æ•°æ®é‡æ“ä½œæ³¨æ„æ€§èƒ½
    
    ğŸ“ˆ é«˜æ•ˆä½¿ç”¨æµç¨‹ï¼š
    1. analyze_data() â†’ äº†è§£æ•°æ®è´¨é‡
    2. process_data("clean") â†’ æ¸…æ´—æ•°æ®
    3. process_data("transform") â†’ è½¬æ¢æ•°æ®
    4. process_data("filter") â†’ ç­›é€‰æ•°æ®
    5. analyze_data() â†’ éªŒè¯å¤„ç†ç»“æœ
    
    ğŸ¯ å…³é”®ç†è§£ç‚¹ï¼š
    - æ¯ç§æ“ä½œç±»å‹æœ‰ç‰¹å®šçš„configæ ¼å¼
    - æ”¯æŒé“¾å¼å¤„ç†ï¼ˆä¸Šä¸€æ­¥è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥è¾“å…¥ï¼‰
    - æä¾›è¯¦ç»†çš„æ“ä½œæ—¥å¿—å’Œç»Ÿè®¡ä¿¡æ¯
    
    ğŸ“‹ é…ç½®ç¤ºä¾‹ï¼š
    ```python
    # æ•°æ®æ¸…æ´—
    config = {
        "remove_duplicates": True,
        "fill_missing": {
            "age": {"method": "mean"},
            "name": {"method": "mode"}
        }
    }
    
    # æ•°æ®ç­›é€‰
    config = {
        "filter_condition": "age > 18 and salary > 5000",
        "select_columns": ["name", "age", "department"]
    }
    
    # æ•°æ®èšåˆ
    config = {
        "group_by": {
            "columns": ["department"],
            "agg": {
                "salary": "mean",
                "age": "count"
            }
        }
    }
    ```
    """
    return process_data_impl(operation_type, data_source, config, target_table)

@mcp.tool()
def export_data(
    export_type: str,
    data_source: str,
    file_path: str = None,
    options: dict = None
) -> str:
    """
    ğŸ“¤ æ•°æ®å¯¼å‡ºå·¥å…· - å°†æ•°æ®å¯¼å‡ºä¸ºå„ç§æ ¼å¼æ–‡ä»¶
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - æ”¯æŒå¤šç§å¯¼å‡ºæ ¼å¼ï¼šExcelã€CSVã€JSON
    - å¯å¯¼å‡ºè¡¨æ•°æ®æˆ–SQLæŸ¥è¯¢ç»“æœ
    - è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨æŒ‡å®šè·¯å¾„
    - æ”¯æŒå¯¼å‡ºé€‰é¡¹è‡ªå®šä¹‰
    
    Args:
        export_type: å¯¼å‡ºæ ¼å¼ç±»å‹
            - "excel": Excelæ–‡ä»¶(.xlsx)
            - "csv": CSVæ–‡ä»¶(.csv)
            - "json": JSONæ–‡ä»¶(.json)
        data_source: æ•°æ®æº
            - è¡¨å: ç›´æ¥å¯¼å‡ºæ•´ä¸ªè¡¨
            - SQLæŸ¥è¯¢: å¯¼å‡ºæŸ¥è¯¢ç»“æœï¼ˆä»¥SELECTå¼€å¤´ï¼‰
        file_path: å¯¼å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            - None: è‡ªåŠ¨ç”Ÿæˆè·¯å¾„åˆ°exports/ç›®å½•
            - æŒ‡å®šè·¯å¾„: ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„
        options: å¯¼å‡ºé€‰é¡¹ï¼ˆå¯é€‰å­—å…¸ï¼‰
            - Excel: {"sheet_name": "å·¥ä½œè¡¨å", "auto_adjust_columns": True}
            - CSV: {"encoding": "utf-8", "separator": ","}
            - JSON: {"orient": "records", "indent": 2}
    
    Returns:
        str: JSONæ ¼å¼çš„å¯¼å‡ºç»“æœï¼ŒåŒ…å«æ–‡ä»¶è·¯å¾„ã€å¤§å°ã€è®°å½•æ•°ç­‰ä¿¡æ¯
    
    ğŸ¤– AIä½¿ç”¨å»ºè®®ï¼š
    1. è¡¨å¯¼å‡ºï¼šexport_data("excel", "table_name")
    2. æŸ¥è¯¢å¯¼å‡ºï¼šexport_data("csv", "SELECT * FROM table WHERE condition")
    3. è‡ªå®šä¹‰æ ¼å¼ï¼šä½¿ç”¨optionså‚æ•°è°ƒæ•´å¯¼å‡ºæ ¼å¼
    4. æ‰¹é‡å¯¼å‡ºï¼šç»“åˆå¾ªç¯å¯¼å‡ºå¤šä¸ªè¡¨æˆ–æŸ¥è¯¢
    
    ğŸ’¡ æœ€ä½³å®è·µï¼š
    - Excelé€‚åˆæŠ¥è¡¨å’Œå¯è§†åŒ–
    - CSVé€‚åˆæ•°æ®äº¤æ¢å’Œå¯¼å…¥å…¶ä»–ç³»ç»Ÿ
    - JSONé€‚åˆAPIå’Œç¨‹åºå¤„ç†
    - å¤§æ•°æ®é‡ä¼˜å…ˆä½¿ç”¨CSV
    
    âš ï¸ å¸¸è§é”™è¯¯é¿å…ï¼š
    - ç¡®ä¿data_sourceå­˜åœ¨ï¼ˆè¡¨åï¼‰æˆ–è¯­æ³•æ­£ç¡®ï¼ˆSQLï¼‰
    - æ–‡ä»¶è·¯å¾„ç›®å½•å¿…é¡»å­˜åœ¨æˆ–å¯åˆ›å»º
    - æ³¨æ„æ–‡ä»¶æƒé™å’Œç£ç›˜ç©ºé—´
    
    ğŸ“ˆ é«˜æ•ˆä½¿ç”¨æµç¨‹ï¼š
    1. ç¡®å®šå¯¼å‡ºéœ€æ±‚ï¼ˆæ ¼å¼ã€å†…å®¹ï¼‰
    2. é€‰æ‹©åˆé€‚çš„export_type
    3. å‡†å¤‡data_sourceï¼ˆè¡¨åæˆ–SQLï¼‰
    4. è®¾ç½®optionsï¼ˆå¦‚éœ€è¦ï¼‰
    5. æ‰§è¡Œå¯¼å‡ºå¹¶æ£€æŸ¥ç»“æœ
    
    ğŸ¯ å…³é”®ç†è§£ç‚¹ï¼š
    - æ”¯æŒè¡¨å’ŒæŸ¥è¯¢ä¸¤ç§æ•°æ®æº
    - è‡ªåŠ¨å¤„ç†æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼
    - æä¾›è¯¦ç»†çš„å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯
    """
    return export_data_impl(export_type, data_source, file_path, options)

# ================================
# APIç®¡ç†å·¥å…·
# ================================

@mcp.tool()
def manage_api_config(
    action: str,
    api_name: str = None,
    config_data: dict = None
) -> str:
    """
    ç®¡ç†APIé…ç½®
    
    Args:
        action: æ“ä½œç±»å‹ (list|test|add|remove|reload|get_endpoints)
        api_name: APIåç§°
        config_data: APIé…ç½®æ•°æ®
    
    Returns:
        str: æ“ä½œç»“æœ
    """
    return manage_api_config_impl(action, api_name, config_data)

@mcp.tool()
def fetch_api_data(
    api_name: str,
    endpoint_name: str,
    params: dict = None,
    data: dict = None,
    method: str = None,
    transform_config: dict = None,
    storage_session_id: str = None
) -> str:
    """
    ä»APIè·å–æ•°æ®å¹¶è‡ªåŠ¨å­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆæ–¹å¼äºŒï¼šè‡ªåŠ¨æŒä¹…åŒ–æµç¨‹ï¼‰
    
    æ³¨æ„ï¼šå·²åˆ é™¤æ–¹å¼ä¸€ï¼ˆæ‰‹åŠ¨æµç¨‹ï¼‰ï¼Œæ‰€æœ‰APIæ•°æ®é»˜è®¤ç›´æ¥å­˜å‚¨åˆ°æ•°æ®åº“
    
    Args:
        api_name: APIåç§°
        endpoint_name: ç«¯ç‚¹åç§°
        params: è¯·æ±‚å‚æ•°
        data: è¯·æ±‚æ•°æ®ï¼ˆPOST/PUTï¼‰
        method: HTTPæ–¹æ³•
        transform_config: æ•°æ®è½¬æ¢é…ç½®
        storage_session_id: å­˜å‚¨ä¼šè¯IDï¼ˆå¯é€‰ï¼Œä¸æä¾›æ—¶è‡ªåŠ¨åˆ›å»ºï¼‰
    
    Returns:
        str: æ•°æ®å­˜å‚¨ç»“æœå’Œä¼šè¯ä¿¡æ¯
    """
    return fetch_api_data_impl(api_name, endpoint_name, params, data, method, transform_config, storage_session_id)

@mcp.tool()
def api_data_preview(
    api_name: str,
    endpoint_name: str,
    params: dict = None,
    max_rows: int = 10,
    max_cols: int = 10,
    preview_fields: list = None,
    preview_depth: int = 3,
    show_data_types: bool = True,
    show_summary: bool = True,
    truncate_length: int = 100
) -> str:
    """
    ğŸ” APIæ•°æ®é¢„è§ˆå·¥å…· - çµæ´»é¢„è§ˆAPIè¿”å›æ•°æ®
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - æ”¯æŒçµæ´»çš„æ•°æ®é¢„è§ˆé…ç½®
    - å¯æŒ‡å®šé¢„è§ˆå­—æ®µå’Œæ·±åº¦
    - æä¾›æ•°æ®ç±»å‹å’Œæ‘˜è¦ä¿¡æ¯
    - é¿å…æ•°æ®æˆªæ–­é—®é¢˜
    
    Args:
        api_name: APIåç§°
        endpoint_name: ç«¯ç‚¹åç§°
        params: è¯·æ±‚å‚æ•°
        max_rows: æœ€å¤§æ˜¾ç¤ºè¡Œæ•° (é»˜è®¤10)
        max_cols: æœ€å¤§æ˜¾ç¤ºåˆ—æ•° (é»˜è®¤10)
        preview_fields: æŒ‡å®šé¢„è§ˆçš„å­—æ®µåˆ—è¡¨ (å¯é€‰)
        preview_depth: JSONåµŒå¥—é¢„è§ˆæ·±åº¦ (é»˜è®¤3)
        show_data_types: æ˜¯å¦æ˜¾ç¤ºæ•°æ®ç±»å‹ä¿¡æ¯ (é»˜è®¤True)
        show_summary: æ˜¯å¦æ˜¾ç¤ºæ•°æ®æ‘˜è¦ (é»˜è®¤True)
        truncate_length: å­—æ®µå€¼æˆªæ–­é•¿åº¦ (é»˜è®¤100)
    
    Returns:
        str: æ•°æ®é¢„è§ˆç»“æœ
        
    ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    # åŸºæœ¬é¢„è§ˆ
    api_data_preview(
        api_name="alpha_vantage",
        endpoint_name="news_sentiment",
        params={"topics": "technology"}
    )
    
    # æŒ‡å®šå­—æ®µé¢„è§ˆ
    api_data_preview(
        api_name="alpha_vantage",
        endpoint_name="news_sentiment",
        params={"topics": "technology"},
        preview_fields=["title", "summary", "sentiment_score"],
        max_rows=5
    )
    
    # æ·±åº¦é¢„è§ˆåµŒå¥—æ•°æ®
    api_data_preview(
        api_name="complex_api",
        endpoint_name="nested_data",
        preview_depth=5,
        truncate_length=200
    )
    ```
    
    ğŸ¯ å…³é”®ç†è§£ç‚¹ï¼š
    - preview_fieldså¯ä»¥ç²¾ç¡®æ§åˆ¶æ˜¾ç¤ºå†…å®¹
    - preview_depthæ§åˆ¶JSONåµŒå¥—æ˜¾ç¤ºå±‚çº§
    - truncate_lengthé¿å…è¶…é•¿å­—æ®µå½±å“æ˜¾ç¤º
    - æä¾›å®Œæ•´çš„æ•°æ®ç»“æ„åˆ†æ
    """
    return api_data_preview_impl(api_name, endpoint_name, params, max_rows, max_cols, preview_fields, preview_depth, show_data_types, show_summary, truncate_length)

@mcp.tool()
def create_api_storage_session(
    session_name: str,
    api_name: str,
    endpoint_name: str,
    description: str = None
) -> str:
    """
    åˆ›å»ºAPIæ•°æ®å­˜å‚¨ä¼šè¯
    
    Args:
        session_name: å­˜å‚¨ä¼šè¯åç§°
        api_name: APIåç§°
        endpoint_name: ç«¯ç‚¹åç§°
        description: ä¼šè¯æè¿°
    
    Returns:
        str: åˆ›å»ºç»“æœ
    """
    return create_api_storage_session_impl(session_name, api_name, endpoint_name, description)

@mcp.tool()
def list_api_storage_sessions() -> str:
    """
    ğŸ“‹ APIå­˜å‚¨ä¼šè¯åˆ—è¡¨å·¥å…· - æŸ¥çœ‹æ‰€æœ‰APIæ•°æ®å­˜å‚¨ä¼šè¯
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - åˆ—å‡ºæ‰€æœ‰APIæ•°æ®å­˜å‚¨ä¼šè¯
    - æ˜¾ç¤ºä¼šè¯è¯¦ç»†ä¿¡æ¯å’Œæ•°æ®ç»Ÿè®¡
    - ä¸ºAPIæ•°æ®å¯¼å…¥æä¾›ä¼šè¯é€‰æ‹©
    
    Returns:
        str: JSONæ ¼å¼çš„ä¼šè¯åˆ—è¡¨ï¼ŒåŒ…å«ä¼šè¯ä¿¡æ¯å’Œæ•°æ®ç»Ÿè®¡
    
    ğŸ¤– AIä½¿ç”¨å»ºè®®ï¼š
    - åœ¨å¯¼å…¥APIæ•°æ®å‰å…ˆæŸ¥çœ‹å¯ç”¨ä¼šè¯
    - é€‰æ‹©åˆé€‚çš„ä¼šè¯è¿›è¡Œæ•°æ®å¯¼å…¥
    - äº†è§£æ¯ä¸ªä¼šè¯çš„æ•°æ®é‡å’Œç»“æ„
    """
    return list_api_storage_sessions_impl()

# ================================
# æœåŠ¡å™¨å¯åŠ¨
# ================================

def main():
    """ä¸»å‡½æ•° - å¯åŠ¨MCPæœåŠ¡å™¨"""
    logger.info("DataMaster MCP æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    logger.info("æ¨¡å—åŒ–æ¶æ„å·²åŠ è½½ï¼š")
    logger.info("  - core/database.py: æ•°æ®åº“ç®¡ç†")
    logger.info("  - core/data_analysis.py: æ•°æ®åˆ†æ")
    logger.info("  - core/data_processing.py: æ•°æ®å¤„ç†")
    logger.info("  - core/api_manager.py: APIç®¡ç†")
    mcp.run()

if __name__ == "__main__":
    main()